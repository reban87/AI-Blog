[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Er. Rebanta Aryal",
    "section": "",
    "text": "Experience Machine Learning Engineer with 4+ years of proven expertise in Natural Language Processing, Machine Learning, Deep Learning. Solving a problem and gaining insights with the help of machine learning algorithms has always seemed to be a superpower for me. I am here to solve things, Learning a lot in the process.\n\nPublication:\n\nA Fire Hazard Assessment Using Sentinel Imagery; A Case Study Over Gippsland Australia\nThematic Mapping Method to Understand Distribution of Agriculture and Animal Production of European Union\nSmoke Detection from Satellite Imagery Using Deep Learning\n\n\n\nExperience:\n\nRippeyAI | NLP Engineer | April 2022 - June 2024\nInspiring Lab | Data Scientist | Oct 2022 - April 2022\nNational College of Engineering | Lecturer | Nov 2018 - Feb 2022"
  },
  {
    "objectID": "posts/tokenization/tokenization.html",
    "href": "posts/tokenization/tokenization.html",
    "title": "Tokenization in Natural Language Processing (NLP)",
    "section": "",
    "text": "Tokenization is a fundamental preprocessing step in Natural Language Processing (NLP) that involves breaking down text into smaller units, called tokens. Tokens are typically words, subwords, or characters, and they serve as the building blocks for various NLP tasks.\n\n\n\n\nText Input : The process begins with a raw text input, which could be a sentence, paragraph, or entire document.\nSentence Splitting: In some cases, the text may be split into sentences, especially when dealing with tasks like text summarization or sentiment analysis at the sentence level.\n\n3.Word Tokenization: The primary step involves breaking the text into word-level tokens. Words are separated by spaces or punctuation marks. For example, the sentence “I love NLP!” would be tokenized into [“I”, “love”, “NLP”, “!”].\n\nSubword Tokenization (optional): In cases where a vocabulary may not cover all words (e.g., rare or out-of-vocabulary words), subword tokenization methods like Byte-Pair Encoding (BPE) or WordPiece are used to break words into smaller units or subword tokens.\nCharacter Tokenization (optional): In some scenarios, character-level tokenization may be employed, where each character is treated as a token. This can be useful for tasks like text generation.\n\n\n\n\n\nText Processing: Tokenization is a crucial step for text processing because it structures the text data into units that can be manipulated and analyzed more easily.\nFeature Extraction: Tokens serve as the basis for extracting features from text, enabling the use of machine learning algorithms for NLP tasks.\nVocabulary Management: Tokenization is closely tied to vocabulary management, as tokens correspond to entries in the vocabulary or word embeddings.\nLanguage Understanding: It helps in understanding the syntactic and semantic structure of the text, which is essential for many NLP tasks like part-of-speech tagging, named entity recognition, and sentiment analysis.\n\n\n\n\n\nAmbiguity: Some words may have multiple meanings or be part of different phrases, leading to ambiguity during tokenization. For instance, “book” can refer to a noun or a verb.\nContractions and Apostrophes: Words with contractions and possessive forms can be challenging. For example, “can’t” could be tokenized as “can” and “’t” or as a single token “can’t.”\nHyphenated Words: Words with hyphens, such as “state-of-the-art,” pose a challenge as they can be tokenized differently depending on the context.\nLanguages with No Spaces: In languages like Chinese and Japanese, words are not separated by spaces, making word tokenization more complex.\nOut-of-Vocabulary (OOV) Words: Tokenization may not handle OOV words well, especially when using fixed vocabularies or subword tokenization methods.\nDomain-Specific Jargon: Tokenizing domain-specific terms and jargon correctly can be challenging, as they may not appear in standard language models’ vocabularies.\nSpecial Characters: Tokenization of special characters, emojis, or code snippets can require specialized handling. Addressing these challenges often involves using advanced tokenization techniques, customizing tokenizers for specific tasks, or employing subword tokenization methods like Byte-Pair Encoding or WordPiece to handle OOV words and linguistic nuances more effectively. Tokenization is a critical preprocessing step in NLP, and its accuracy can significantly impact the performance of downstream NLP tasks."
  },
  {
    "objectID": "posts/tokenization/tokenization.html#tokenization-in-nlp",
    "href": "posts/tokenization/tokenization.html#tokenization-in-nlp",
    "title": "Tokenization in Natural Language Processing (NLP)",
    "section": "",
    "text": "Tokenization is a fundamental preprocessing step in Natural Language Processing (NLP) that involves breaking down text into smaller units, called tokens. Tokens are typically words, subwords, or characters, and they serve as the building blocks for various NLP tasks.\n\n\n\n\nText Input : The process begins with a raw text input, which could be a sentence, paragraph, or entire document.\nSentence Splitting: In some cases, the text may be split into sentences, especially when dealing with tasks like text summarization or sentiment analysis at the sentence level.\n\n3.Word Tokenization: The primary step involves breaking the text into word-level tokens. Words are separated by spaces or punctuation marks. For example, the sentence “I love NLP!” would be tokenized into [“I”, “love”, “NLP”, “!”].\n\nSubword Tokenization (optional): In cases where a vocabulary may not cover all words (e.g., rare or out-of-vocabulary words), subword tokenization methods like Byte-Pair Encoding (BPE) or WordPiece are used to break words into smaller units or subword tokens.\nCharacter Tokenization (optional): In some scenarios, character-level tokenization may be employed, where each character is treated as a token. This can be useful for tasks like text generation.\n\n\n\n\n\nText Processing: Tokenization is a crucial step for text processing because it structures the text data into units that can be manipulated and analyzed more easily.\nFeature Extraction: Tokens serve as the basis for extracting features from text, enabling the use of machine learning algorithms for NLP tasks.\nVocabulary Management: Tokenization is closely tied to vocabulary management, as tokens correspond to entries in the vocabulary or word embeddings.\nLanguage Understanding: It helps in understanding the syntactic and semantic structure of the text, which is essential for many NLP tasks like part-of-speech tagging, named entity recognition, and sentiment analysis.\n\n\n\n\n\nAmbiguity: Some words may have multiple meanings or be part of different phrases, leading to ambiguity during tokenization. For instance, “book” can refer to a noun or a verb.\nContractions and Apostrophes: Words with contractions and possessive forms can be challenging. For example, “can’t” could be tokenized as “can” and “’t” or as a single token “can’t.”\nHyphenated Words: Words with hyphens, such as “state-of-the-art,” pose a challenge as they can be tokenized differently depending on the context.\nLanguages with No Spaces: In languages like Chinese and Japanese, words are not separated by spaces, making word tokenization more complex.\nOut-of-Vocabulary (OOV) Words: Tokenization may not handle OOV words well, especially when using fixed vocabularies or subword tokenization methods.\nDomain-Specific Jargon: Tokenizing domain-specific terms and jargon correctly can be challenging, as they may not appear in standard language models’ vocabularies.\nSpecial Characters: Tokenization of special characters, emojis, or code snippets can require specialized handling. Addressing these challenges often involves using advanced tokenization techniques, customizing tokenizers for specific tasks, or employing subword tokenization methods like Byte-Pair Encoding or WordPiece to handle OOV words and linguistic nuances more effectively. Tokenization is a critical preprocessing step in NLP, and its accuracy can significantly impact the performance of downstream NLP tasks."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my blog!",
    "section": "",
    "text": "Tokenization in Natural Language Processing (NLP)\n\n\n\n\n\n\ntokens\n\n\nembeddings\n\n\nNLP\n\n\nvector\n\n\ntransformers\n\n\n\n\n\n\n\n\n\nJun 26, 2024\n\n\nEr.Rebanta Aryal\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Docker\n\n\n\n\n\n\ndocker\n\n\ncontainers\n\n\ncloud computing\n\n\nmicroservices\n\n\ntechnology\n\n\nservices\n\n\n\n\n\n\n\n\n\nOct 23, 2022\n\n\nEr.Rebanta Aryal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Docker/docker.html",
    "href": "posts/Docker/docker.html",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and ship it all out as one package.\nDocker is an open source project that automates the deployment of applications inside software containers ## How Docker works? \nA developer will define all the applications and its dependencies and its requirements which is called as Docker File.\nDocker File can be used to create Docker Images\nWhen we run docker image, we will get Docker Containers. So docker containers are the run time instances of docker image and these images can also be stored in an online cloud repositories which is Docker Hub\nIn Docker Hub , there are many publicly available images and you can store your own docker images as well.\nThis image can be pulled to any environment like staging environment or test environment.\n\n\n\n\n\n - The daemon (server) receives the commands from the Docker client through CLI or REST API’s - Docker client and daemon can be present on the same host (machine) or different hosts\n\n\n\n\nsudo yum -y update\nsudo yum install -y docker\ndocker\ndocker --version\n\n\n\n\n\nstart docker\nsudo service docker start\nsudo usermod-a-G docker \"user\"\ndocker info\ndocker run hello-world : to run hello-world image\ndocker images : to get list of images present locally\ndocker ps : to get list of runnig containers\ndocker ps-a : to get list of all containers\n\n\n\n\nsudo service docker stop\n\n\n\nsudo yum remove docker\n\n\n\n\nInstallation Related\nInstallation Steps for amazon ec2"
  },
  {
    "objectID": "posts/Docker/docker.html#what-is-docker",
    "href": "posts/Docker/docker.html#what-is-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and ship it all out as one package.\nDocker is an open source project that automates the deployment of applications inside software containers ## How Docker works? \nA developer will define all the applications and its dependencies and its requirements which is called as Docker File.\nDocker File can be used to create Docker Images\nWhen we run docker image, we will get Docker Containers. So docker containers are the run time instances of docker image and these images can also be stored in an online cloud repositories which is Docker Hub\nIn Docker Hub , there are many publicly available images and you can store your own docker images as well.\nThis image can be pulled to any environment like staging environment or test environment."
  },
  {
    "objectID": "posts/Docker/docker.html#client-server-architecture-of-docker",
    "href": "posts/Docker/docker.html#client-server-architecture-of-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "- The daemon (server) receives the commands from the Docker client through CLI or REST API’s - Docker client and daemon can be present on the same host (machine) or different hosts"
  },
  {
    "objectID": "posts/Docker/docker.html#install-docker-in-linux",
    "href": "posts/Docker/docker.html#install-docker-in-linux",
    "title": "Introduction to Docker",
    "section": "",
    "text": "sudo yum -y update\nsudo yum install -y docker\ndocker\ndocker --version"
  },
  {
    "objectID": "posts/Docker/docker.html#start-docker",
    "href": "posts/Docker/docker.html#start-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "start docker\nsudo service docker start\nsudo usermod-a-G docker \"user\"\ndocker info\ndocker run hello-world : to run hello-world image\ndocker images : to get list of images present locally\ndocker ps : to get list of runnig containers\ndocker ps-a : to get list of all containers"
  },
  {
    "objectID": "posts/Docker/docker.html#stop-docker",
    "href": "posts/Docker/docker.html#stop-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "sudo service docker stop"
  },
  {
    "objectID": "posts/Docker/docker.html#uninstall-docker",
    "href": "posts/Docker/docker.html#uninstall-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "sudo yum remove docker"
  },
  {
    "objectID": "posts/Docker/docker.html#helpful-links",
    "href": "posts/Docker/docker.html#helpful-links",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Installation Related\nInstallation Steps for amazon ec2"
  }
]